{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv\n",
    "from torch_geometric.data import Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1]])\n",
      "tensor([0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Let's say our traffic_action is 2 (representing the third option: \n",
    "# \"allow vehicular traffic through North-East and South-West direction\")\n",
    "traffic_action = torch.tensor([1])\n",
    "\n",
    "# We have 4 possible traffic light states, so num_classes is 2\n",
    "one_hot_action = F.one_hot(traffic_action, num_classes=2)\n",
    "\n",
    "print(one_hot_action)\n",
    "# Output: tensor([[0, 0, 1, 0]])\n",
    "\n",
    "# If we remove the extra dimension:\n",
    "print(one_hot_action.squeeze())\n",
    "# Output: tensor([0, 0, 1, 0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task: Propose variable number of tuples using GAT in a RL setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pyg-team/pytorch_geometric/blob/master/examples/gat.py\n",
    "# In the original model, expected input: \n",
    "# 1. x: Node feature matrix with shape [num_nodes, in_channels]\n",
    "    # num_nodes: number of nodes in the graph\n",
    "    # in_channels: number of node features\n",
    "\n",
    "# 2. edge_index: Edge indices with shape [2, num_edges]\n",
    "    # num_edges: number of edges in the graph\n",
    "    # example: edge_index = torch.tensor([[0, 1, 2, 3], [1, 2, 3, 0]], dtype=torch.long)\n",
    "    # edge exists from node 0 to node 1, 1 to 2, 2 to 3, and 3 to 0\n",
    "\n",
    "# Expected output:\n",
    "# 1. x: Updated node feature matrix with shape [num_nodes, out_channels]\n",
    "    # num_nodes: number of nodes in the graph\n",
    "    # out_channels: number of output features\n",
    "\n",
    "# 2. edge_index: Updated edge indices with shape [2, num_edges]\n",
    "    # num_edges: number of edges in the graph\n",
    "\n",
    "# So what the GAT model is \"learning to create new, more informative representations of each node based on its own features and the features of its neighbors\"\n",
    "# Learn better representations based on the graph structure.\n",
    "# The core idea about GATs is to update node representations by aggregating information from their neighbors.\n",
    "# Capture local graph structure and node features.\n",
    "# The attention in GAT refers to the model's ability to weigh the importance of different neighbors differently. Not all neighbors are equally important.\n",
    "\n",
    "# With 2 GAT layers, the model can incorporate information from node's 2-hop neighborhood. \n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, heads):\n",
    "        \"\"\"\n",
    "        heads: number of attention heads\n",
    "\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = GATConv(in_channels, hidden_channels, heads, dropout=0.6)\n",
    "        # On the Pubmed dataset, use `heads` output heads in `conv2`.\n",
    "\n",
    "        # output layer has one head.\n",
    "        self.conv2 = GATConv(hidden_channels * heads, out_channels, heads=1,\n",
    "                             concat=False, dropout=0.6)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = F.elu(self.conv1(x, edge_index))\n",
    "\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified GAT for the RL setup.\n",
    "# Based on the input state, propose a variable number of tuples.\n",
    "\n",
    "# Input: \n",
    "# 1. Node feature matrix with shape [num_nodes, in_channels]\n",
    "    # num_nodes: number of nodes in the graph\n",
    "    # in_channels: number of node features\n",
    "\n",
    "# 2. Edge indices with shape [2, num_edges]\n",
    "    # num_edges: number of edges in the graph\n",
    "\n",
    "# Output:\n",
    "# 1. N Tuples of (locations, thickness)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup below: \n",
    "\n",
    "- Model structure: \n",
    "    - 2 GAT layers\n",
    "    - SeparateLinear layers for predicting location parameters, thickness parameters, and number of proposals\n",
    "\n",
    "- Proposal generation:\n",
    "    - Core to the policy, generate stochastic proposals. \n",
    "\n",
    "\n",
    "\n",
    "Using a GAT allows us to naturally take variable sized input.\n",
    "However, we are still operating under the purview of RL, which asks us to have fixed sized input. \n",
    "\n",
    "To resolve that we can use (this is a common practice):\n",
    "- a maximum number of proposals to define the action space and pad then the ones that are not proposed.\n",
    "- a maximum number of nodes, edges to define the state space and pad accordingly.\n",
    "\n",
    "Make sure that the PPO algorithm is aware of the masking so that it does not try to learn from or\n",
    "\n",
    "Also this uses GAT v2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 10, Number of edges: 20\n",
      "Number of node features: 2, Number of edge features: 2\n",
      "Input data: \n",
      "Node features: tensor([[0.8292, 0.2036],\n",
      "        [0.7067, 0.1631],\n",
      "        [0.3717, 0.7307],\n",
      "        [0.8826, 0.5376],\n",
      "        [0.3398, 0.3567],\n",
      "        [0.7639, 0.0156],\n",
      "        [0.2888, 0.3420],\n",
      "        [0.1353, 0.2934],\n",
      "        [0.7088, 0.6415],\n",
      "        [0.0506, 0.2979]])\n",
      "Edge indices: tensor([[3, 3, 8, 9, 8, 7, 8, 3, 3, 7, 7, 0, 5, 0, 2, 0, 6, 1, 8, 8],\n",
      "        [5, 4, 0, 4, 3, 1, 7, 5, 7, 3, 2, 6, 8, 2, 7, 9, 8, 5, 0, 9]])\n",
      "Edge features: tensor([[0.7337, 0.3222],\n",
      "        [0.1443, 0.4561],\n",
      "        [0.4512, 0.8670],\n",
      "        [0.4517, 0.9976],\n",
      "        [0.1814, 0.4896],\n",
      "        [0.5131, 0.4759],\n",
      "        [0.5964, 0.9999],\n",
      "        [0.1735, 0.9213],\n",
      "        [0.7353, 0.6507],\n",
      "        [0.1911, 0.3615],\n",
      "        [0.4897, 0.4718],\n",
      "        [0.9423, 0.9385],\n",
      "        [0.5673, 0.5662],\n",
      "        [0.1150, 0.3849],\n",
      "        [0.4931, 0.0195],\n",
      "        [0.3387, 0.3835],\n",
      "        [0.2155, 0.4800],\n",
      "        [0.5324, 0.0467],\n",
      "        [0.6589, 0.1817],\n",
      "        [0.1157, 0.0076]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATv2Conv\n",
    "\n",
    "class EdgeFeatureGATConv(GATv2Conv):\n",
    "    \"\"\"\n",
    "    Apply Graph Attention to the input graph with edge features.\n",
    "    By default supports edge features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, edge_dim, heads=1, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, heads=heads, edge_dim=edge_dim, **kwargs)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        return super().forward(x, edge_index, edge_attr=edge_attr)\n",
    "\n",
    "class GATCrosswalkPolicy(torch.nn.Module):\n",
    "    def __init__(self, in_channels, edge_dim, hidden_channels, heads, max_proposals=10, min_thickness=0.1, max_thickness=10.0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # First Graph Attention layer with edge features\n",
    "        self.conv1 = EdgeFeatureGATConv(in_channels, hidden_channels, edge_dim=edge_dim, heads=heads, dropout=0.6)\n",
    "        \n",
    "        # Second Graph Attention layer with edge features\n",
    "        self.conv2 = EdgeFeatureGATConv(hidden_channels * heads, hidden_channels, edge_dim=edge_dim, heads=1, concat=False, dropout=0.6)\n",
    "        \n",
    "        # Linear layer for predicting location parameters (mean and log std)\n",
    "        self.location_layer = torch.nn.Linear(hidden_channels, 2)\n",
    "        \n",
    "        # Linear layer for predicting thickness parameters (mean and log std)\n",
    "        self.thickness_layer = torch.nn.Linear(hidden_channels, 2)\n",
    "        \n",
    "        # Linear layer for predicting the number of proposals\n",
    "        self.num_proposals_layer = torch.nn.Linear(hidden_channels, max_proposals)\n",
    "        \n",
    "        # Store initialization parameters as instance variables\n",
    "        self.max_proposals = max_proposals\n",
    "        self.min_thickness = min_thickness\n",
    "        self.max_thickness = max_thickness\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        # Apply dropout to input features for regularization\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        \n",
    "        # Apply first GAT layer with edge features and ELU activation\n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        \n",
    "        # Apply dropout to hidden representations\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        \n",
    "        # Apply second GAT layer with edge features (no activation here as it's the final layer)\n",
    "        x = self.conv2(x, edge_index, edge_attr)\n",
    "        \n",
    "        return x  # Return the final node embeddings\n",
    "\n",
    "    def propose_crosswalks(self, x, edge_index, edge_attr):\n",
    "        # Get node embeddings by passing input through GAT layers\n",
    "        node_embeddings = self(x, edge_index, edge_attr)\n",
    "        \n",
    "        # Predict the number of proposals\n",
    "        num_proposals_logits = self.num_proposals_layer(node_embeddings.mean(dim=0))\n",
    "        num_proposals_probs = F.softmax(num_proposals_logits, dim=0)  # Convert to probabilities\n",
    "        # Sample the number of proposals (add 1 to ensure at least 1 proposal)\n",
    "        num_actual_proposals = torch.multinomial(num_proposals_probs, 1).item() + 1\n",
    "        \n",
    "        # Predict location parameters\n",
    "        location_params = self.location_layer(node_embeddings)\n",
    "        location_means = torch.sigmoid(location_params[:, 0])  # Ensure means are between 0 and 1\n",
    "        location_log_stds = location_params[:, 1].clamp(-20, 2)  # Clamp log stds for numerical stability\n",
    "        location_stds = torch.exp(location_log_stds)  # Convert log stds to stds\n",
    "        \n",
    "        # Sample locations from normal distribution\n",
    "        locations = torch.normal(location_means, location_stds)\n",
    "        locations = torch.clamp(locations, 0, 1)  # Ensure sampled locations are between 0 and 1\n",
    "        \n",
    "        # Predict thickness parameters\n",
    "        thickness_params = self.thickness_layer(node_embeddings)\n",
    "        # Scale thickness means to be between min_thickness and max_thickness\n",
    "        thickness_means = torch.sigmoid(thickness_params[:, 0]) * (self.max_thickness - self.min_thickness) + self.min_thickness\n",
    "        thickness_log_stds = thickness_params[:, 1].clamp(-20, 2)  # Clamp log stds for numerical stability\n",
    "        thickness_stds = torch.exp(thickness_log_stds)  # Convert log stds to stds\n",
    "        \n",
    "        # Sample thicknesses from normal distribution\n",
    "        thicknesses = torch.normal(thickness_means, thickness_stds)\n",
    "        # Ensure sampled thicknesses are between min_thickness and max_thickness\n",
    "        thicknesses = torch.clamp(thicknesses, self.min_thickness, self.max_thickness)\n",
    "        \n",
    "        # Create fixed-size output with padding\n",
    "        output = torch.full((self.max_proposals, 2), -1.0)\n",
    "        indices = torch.randperm(x.size(0))[:num_actual_proposals]\n",
    "        output[:num_actual_proposals, 0] = locations[indices]\n",
    "        output[:num_actual_proposals, 1] = thicknesses[indices]\n",
    "        \n",
    "        return output, num_actual_proposals  # Return the padded proposals and the number of actual proposals\n",
    "\n",
    "# Example usage\n",
    "in_channels = 2  # Number of input features per node (e.g., x and y coordinates)\n",
    "edge_dim = 2  # Number of features per edge\n",
    "hidden_channels = 16  # Number of hidden units in GAT layers\n",
    "heads = 4  # Number of attention heads in first GAT layer\n",
    "\n",
    "num_nodes = 10  # Maximum number of nodes in the graph (potential crosswalk locations)\n",
    "num_edges = 20  # Maximum number of edges in the graph\n",
    "\n",
    "# Initialize the model with specified parameters\n",
    "model = GATCrosswalkPolicy(in_channels, edge_dim, hidden_channels, heads, max_proposals=10, min_thickness=0.1, max_thickness=10.0)\n",
    "\n",
    "# Create dummy input data\n",
    "x = torch.rand((num_nodes, in_channels))  # Random node features\n",
    "edge_index = torch.randint(0, num_nodes, (2, num_edges))  # Random edges connecting nodes\n",
    "edge_attr = torch.rand((num_edges, edge_dim))  # Random edge features\n",
    "\n",
    "\n",
    "print(f\"Number of nodes: {num_nodes}, Number of edges: {num_edges}\")\n",
    "print(f\"Number of node features: {in_channels}, Number of edge features: {edge_dim}\")\n",
    "\n",
    "print(\"Input data: \")\n",
    "print(f\"Node features: {x}\")\n",
    "print(f\"Edge indices: {edge_index}\")\n",
    "print(f\"Edge features: {edge_attr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Generate crosswalk proposals using the model\n",
    "proposed_crosswalks, num_actual_proposals = model.propose_crosswalks(x, edge_index, edge_attr)\n",
    "\n",
    "# Print the proposed crosswalks\n",
    "print(\"Proposed crosswalks:\")\n",
    "for i, (location, thickness) in enumerate(proposed_crosswalks):\n",
    "    if i < num_actual_proposals:\n",
    "        print(f\"Location: {location:.4f}, Thickness: {thickness:.2f}\")\n",
    "    else:\n",
    "        print(f\"Padded proposal: {location:.4f}, {thickness:.2f}\")\n",
    "print(f\"Number of actual proposals: {num_actual_proposals}\")\n",
    "print(f\"Total number of proposals (including padding): {len(proposed_crosswalks)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
